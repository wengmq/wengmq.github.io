
Ollama 是一个开源的本地大语言模型运行框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。

Ollama 支持多种操作系统，包括 macOS、Windows、Linux 以及通过 Docker 容器运行。

Ollama 提供对模型量化的支持，可以显著降低显存要求，使得在普通家用计算机上运行大型模型成为可能


- Ollama 教程
	- https://www.runoob.com/ollama/ollama-tutorial.html
- Ollama支持的大模型列表
	- https://ollama.com/library